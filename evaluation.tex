\section{Evaluation}
\label{sec:eval}
We have wrote several web applications on top of \cb{} to test its
performance and scalability.
One application is click application,
it increments and prints a counter on HTML whenever the user clicks.
This application represents applications with simple user interactions and small amount of DOM elements.
Other applications are chat applications.
A user can join a chat room to chat with other people,
changes his nickname, send messages, view recent messages in the chat room.
Whenever the number of messages in a chat room reaches 100, the first 50 messages
are discarded.
The chat applications represents more sophisticated applications.
We implemented the chat applications use popular web frameworks Angular and JQuery
to assess how \cb{} performs with real world web technology stack.

\chatroomfig{}

We implemented a benchmark tool to simulate multiple users.
Each simulated user sends HTTP requests the same way as
a web browser does when an actual user is interacting with a web application.
In the benchmarks, each simulated user will wait for its action taking effect before 
sending the next one.
For example, in the click application, the client will wait for the counter
to be refreshed before clicking again.
In the chat application, the client will wait for
the chat message appearing on the chat window before sending another one.
To be efficient, the simulated user does not render the view, 
it just analyzes server's response messages to assess 
if its action has been processed by the server.
For example, after processing a chat message, 
the chat application will create a new DIV element with the chat message content
and append that DIV element to the DOM tree, 
the simulated user will know a chat message is processed after it received
a DOM update message containing that chat message's content.
% TBD

The \cb{} system is deployed on a server with 8 Intel 2.27GHz cores and 12G memory.
The benchmark tool is deployed on a separate machine.

\subsection{Click Application}
In this benchmark,
we allocate a separate virtual browser for each simulated user,
the simulated user will click on the page, 
then wait for the counter to be refreshed and click again.
The application is just a 14 lines HTML document with 5 lines in-line \js{} code.
The \js{} code registers a \emph{onclick} handler on a DIV element,
the \emph{onclick} handler increment a \emph{counter} variable and set the DIV's innerHTML as
the counter every time it is invoked.
% one DOMRemove one DOMInsert event
\clickthroughput{}

Figure~\ref{fig:clickthroughput} shows the throughput of the application 
under different concurrent levels.
Each line represents a \cb{} system with different numbers of worker nodes.
The throughput scales linearly up to 4 workers.
There are two reasons why the result for 8 workers is suboptimal:
First, there are only 8 cores on the machine for 9 server processes.
In the experiments with 4 workers, each worker nodes take 100\% CPU utilization
under the benchmark workload.
With 8 workers, no worker node can monopolize a core and it is common that
a worker node can only take about 60\% CPU usage under the benchmark workload. 
% http://rnikola.cs.vt.edu:2000/logs/dec28/test991_data/test991.md
Second, 
the master node's capacity cannot support $12000$ events per second.
The master node already takes nearly 100\% CPU for $9000$ events per second.


\clicklatency{}

Figure~\ref{fig:clicklatency} is the latency of the application.
A usability study shows that the users feel instantaneous if the 
the application response time is below 100ms.
With this criteria,
\cb{} with 8 workers can sustain 800 concurrent users with an acceptable latency (93ms).

This test scenario does not model real clients because real clients cannot 
interact with user interface with such high speed.
To model real users, we configure the simulated users to pause for a while
after it received the server's response for the previous action.
The pause time is uniformly distributed from 1 second to 2 seconds.
The throughput and latency for this configuration is shown 
in Figure~\ref{fig:clickwaitthroughput} and Figure~\ref{fig:clickwaitlatency} respectively.
In this setting, the capacity of the system is much greater than before.
Using 1 worker, the system could support 2,000 concurrent clients with the average latency 66ms.
Using 8 workers, 
the system can support 10,000 concurrent clients with 8 workers with a latency of 52ms.
As the Figure~\ref{fig:clickwaitlatency} shows, 
the system with 2 workers is twice the capacity than with 1 worker,
% FIXME more analysis



\clickwaitthroughput{}
\clickwaitlatency{}

\subsection{Chat Applications}
As in Fig.\ref{fig:appinstance},
we use \appins{}s to maintain application state of chat rooms.
The virtual browsers use the \emph{ChatRoom} objects inside their \appins{}s 
directly to render the chat history window.
The user can request \emph{Application URL} http://example.com/chat
to create a new chat room.
For example, if 
\emph{userA} requests http://example.com/chat,
an \appins{} and a virtual browser will be created.
Let's say the \appins{}'s id is \emph{appins1},
the virtual browser's id is \emph{vb1}.
\emph{appins1} has an \emph{ChatRoom} object that is used to store 
a chat room's application state.
\emph{vb1} represents \emph{userA}'s view of the newly created
chat room.
If another user \emph{userB} wants to join the chat room, 
he needs to request \emph{appins1}'s \emph{\appins{} URL} 
http://example.com/chat/a/appins1.
The system will create a new virtual browser inside \emph{appins1}
as \emph{userB}'s view.


In the benchmark, 
the simulated users will be grouped into groups of five.
At the beginning of the benchmark, 
for every group one user will request for Application URL to make 
\cb{} create an \appins{},
after that, the remaining users will use the \appins{} URL to start
their own session.
Thus, in the benchmark every five simulated user will share a chat room.

Each simulated user will send 300 chat messages in the chat room it is in.
Each chat message is a sentence of 15-20 characters.
Every time after a simulated user send a message,
it would wait for this message rendered on the chat history window,
pause for 5-10 seconds,
and then send another message.
The pause is simulating the time for a human to think and type a message.
In the beginning to the benchmark, 
we add a 0-10 seconds wait time for each client before they get started.

We measure the time between the moment 
the user hit the enter key to send the message and
when the message is echoed back as latency of the chat application.


% The simulated user will perform the following actions:
% \begin{enumerate}
% \item Sleeps for 0-20 seconds. This is simulating the users enter the 
% chat room at different times.

% \item Double click the welcome panel to show the user name editing input box.

% \item Input a new name in the user name editing input box and hit enter.

% \item \label{itm:chatinput} Input a 15-20 character sentence in the chat message input box and hit enter.

% \item Sleeps for 5-10 seconds and repeat step ~\ref{itm:chatinput} 
% until the user has sent 300 messages. 
% This is simulating the time for the user to think and type a message.

% \end{enumerate}


% In section \ref{sec:angular} and \ref{sec:jquery}, 
% we will discuss the benchmark

% http://www.ng-newsletter.com/posts/directives.html

\subsubsection{Angular Chat Application}
\label{sec:angular}
Angular.js~\cite{angular} is a \js{} framework that enable the developers to 
use HTML elements to declare dynamic views.
In this application, we also use bootstrap CSS framework for styling.

Fig.\ref{fig:angularchatlatency} shows the latency perceived by benchmark tool
at different workload.
The system can support much fewer concurrent clients than the click application.
With 8 workers, the system can support 700 concurrent users with average latency 
of 90ms.
First of all, it is a much more complex application than the click application,
the system needs more memory and CPU resource to support each user.
The increased memory usage would trigger more garbage collection cycles,
which would further slows down the application.
Second, every time the user sends a message, the view of other virtual browsers
in the same chat room needs to be updated as well.
Third, Angular.js brings a substantial overhead 
to pay for the price of friendly programming interface: % confirm, compile ~ link
Angular will walk through the messages list to find out newly created
message objects,
then Angular appends template DOM elements for each new message objects,
finally Angular updates the template DOM elements with the real content of the 
message objects.
Even for desktop web browsers, the list rendering speed of Angular.js
receives widely complaints.% FIXME citation

Some extra effort is required to make Angular work in our system.
First, if the model object is shared in multiple virtual browsers like this application,
we need to notify other virtual browsers to update their view.
A typical Angular application does not need to update the view explicitly because
Angular would detect model object change and update the view automatically 
after every method's invocation(to be precise, these methods should be declared using Angular's API).
In our environment, angular code in one virtual browser does not know the model object
is changed by some methods in another virtual browser.
However, the code for notify and update the view is just 23 lines of code.
Second, angular use an incremented counter to generate ids to identify objects in an array when the 
array is used in a \emph{ng-repeat} loop.
As we have shared objects for multiple virtual browsers,
different objects created in different virtual browsers could be assigned with duplicate 
ids by different Angular instances.
We create an API to assign unique ids to objects to avoid this problem.
The programmer must call this API before put an object into a data structure that is shared
by multiple virtual browsers.
This problem could also be avoid by letting Angular tracking objects by their position in the array,
we do not use this solution for performance considerations.


\angularchatlatency{}

\subsubsection{JQuery Chat Application}
\label{sec:jquery}
To assess the applications written in simpler \js{} libraries,
we write an application with exactly the same functionality and 
appearance with the Angular Chat Application in the previous section.
In this application, we use JQuery to manipulate DOM elements.
We also use handlebars.js to create DOM elements based on templates
because writing code manually to generate DOM elements based on dynamic data 
is error prone and difficult to maintain.
To remove compilation overhead of handlebar.js, 
we pre-compiled templates into \js{} functions and save the compiled code as static files.
We also use moment.js to do date time formatting as there is no built in support 
in JQuery.
Like the previous application, we use bootstrap for styling.
Compared to Angular, JQuery is less expressive so we need
extra libraries to write maintainable code.
The \js{} plus HTML code for Angular Chat Application is 209 lines long,
for this application it is 258 lines long.
Even taking account of 4 lines API support for Angular.js, 
using Angular.js requires less coding than JQuery.
The code in Angular Chat Application is also more readable,
thanks to the data DOM binding in Angular.

However, this application has a much better performance than Angular 
Chat Application because we have more control over how the view
are updated.
We do not scan over the whole list of messages to find updated ones
because we know which ones are new and which ones need to be removed.
Fig.\ref{fig:jquerychatlatency} shows latency of JQuery Chat.
The system can support 1,800 concurrent users with 99ms latency.
It is more than two times of the capacity of Angular Chat Application.

\jquerychatlatency{}


% code space is part of heapTotal. http://jayconrod.com/posts/55/a-tour-of-v8-garbage-collection
\subsection{Memory Consumption}
We use \nodejs{} process.memoryUsage() API to measure the memory usage of each process
of the system.
The function will return \emph{rss}, \emph{heapTotal}, and \emph{heapUsed} of the process.
The \emph{rss} is the size of memory held in RAM by the process.
The \emph{heapTotal} is the size of V8's heap, it is further divided into 
multiple spaces for generational garbage collector and JIT compiler.
The \emph{heapUsed} is the size of heap that the program is currently using,
it includes the size of dead objects that is not garbage collected yet.
It is not clear how much memory a \nodejs{} process actually needs from these statistics.
The \emph{heapUsed} value is the best approximation but it could still contain
ephemeral objects that are not collected by garbage collector.
For our system, the memory consumption is affected by multiple factors:
the code size of web applications, the request rate of clients, 
the number of virtual browsers, how web applications allocate objects, etc.
We set up a minimum \cb{} system (1 master node and 1 worker node)
and run the same type of experiments on JQuery Chat Application as mentioned in Section~\ref{sec:jquery}.
Every 5 seconds, the \cb{} processes will call memoryUsage method and print out
memory statistics.
We create test load for 100,200, and 300 concurrent clients in the three experiments.
% To get a more accurate view of memory consumption at start up time and idle time,
% we make \cb{} processes call \emph{gc} directly after the processes initialize and after
% the benchmark programs completes.

\memfig{}

Figure~\ref{fig:mem} shows memory statistics of worker node under these experiments.
We record four sets of memory statistics for each experiment: 
when the system finishes initialization and called \emph{gc} to trigger a round of garbage collection,
denoted by \emph{startUp};
after the system creates all the virtual browsers for clients and before the clients send 
events, referred as \emph{beforeWorkload};
the maximum value of each memory statistics during the experiment, denoted by \emph{peak};
after the benchmark tool finishes sending events and the system called \emph{gc} again,
denoted by \emph{afterWorkload}.
We consider the following statistics would be interesting to note:
$M_{idle}$, the amount of heap size required when the system sits idle;
$M_{browser}$, the size to support a new virtual browser;
$M_{browserp}$ as the size taken by each virtual browser in \emph{peak}, 
it includes the intermediate objects created during client requests.
% $M_{browser3}$ as the size taken by each virtual browser after benchmark.
We use $h$ as \emph{heapUsed} value, $C$ as client count.
It is easy to see that:
\begin{enumerate}
\item $M_{idle} \leq Min(h_{startUp}, h_{beforeWorkload}, h_{peak}, h_{afterWorkload})$
\item $M_{browser} \leq (h_{beforeWorkload} - M_{idle})/C$
\item $M_{browserp} \leq (h_{peak} - M_{idle})/C$
% \item $M_{browser3} \leq (h_{afterWorkload} - M_{idle})/C$
\end{enumerate}
Because we do not know the exact value of $M_{idle}$, 
we will assume $M_{idle}=0$ for the latter two formulas.
After analysis, $M_{idle} \leq 64.86MB$, $M_{browser} \leq 3.08MB$, $M_{browserp} \leq 5.88MB$.
One might find it counter instinct that during peak time,
the worker node under 200 clients use about the same amount memory as it under 300 clients.
A closer look reveals that under 300 clients, 
garbage collector is more active and thus keeps down the memory print.

The master node has a much lower memory foot print because of its simple logic
and internal state.
Under workload, the master node will take more space to manage connections and
copy network messages back and forth.
Besides that, there is no discernible difference among \emph{startUp}, \emph{beforeWorkload},
and \emph{afterWorkload}.
For master node,
$M_{idle} \leq 17.03MB$ , $M_{browser} \leq 57KB$.
$57KB$ seems unreasonably big because we assume $M_{idle}=0$ in calculation,
if we assume $M_{idle}=17MB$, then $M_{browser} = 0.1K$. 
In reality, $M_{browser}$ would be very small because we only store \appins{}
level information on master using very simple data structures.

For simple applications with simple application state, the memory footprint would be mush smaller.
The JQuery Chat application's code size is 263KB, while the click application is only 0.3KB.
We have run more than 14,000 virtual browsers running click application in a 12GB box without
experiencing any thrashing.

% FIXME
In \nodejs{}, we have few options to configure the garbage collector's behavior.
For example, we do not have the option to specify a minimum heap size to save
the cost of allocating memory when the system is process client requests.
Also, V8 is conservative about requesting more memory from the operating system, % need citation
it will try to reclaim memory by performing several garbage collection cycles before 
allocate more memory for heap, % is this true for all garbage collection systems?
which further slows down the application.

Figure~\ref{fig:mem} also implies the system would spend more time on garbage collection if
the application accumulates memory in a faster pace.
Under 300 concurrent clients, the system experience more garbage collection cycles as
well as higher CPU usage during garbage collection.
% TODO

\subsection{Third Party Libraries}
Although we have not done an extensive evaluation of third party libraries we use,
we notice several issues that could greatly hurt the overall performance.

We use \jsdom{} to implement the server side DOM tree,
\jsdom{}'s implementation of \emph{getComputedStyle} function runs slow in our test applications.
This function computes an element's CSS properties by apply all active style rules~\cite{wilson2000document}.
The very first invocation of \emph{getComputedStyle} in a virtual browser when it
is initializing and loading style rules takes more than 200ms, 
after that each invocation takes 10~20ms.
The situation is exacerbated by the fact that some functions might call \emph{getComputedStyle}
multiple times.
For example, JQuery's \emph{toggle} function calls \emph{getComputedStyle} three times.
There are many ways to alleviate this problem:
We could use less style rules in our applications, the less styles we define,
the faster \emph{getComputedStyle} executes;
We could modify libraries like JQuery to call \emph{getComputedStyle} less often
by cache the return of \emph{getComputedStyle} whenever possible;
Avoid \emph{getComputedStyle} by using less expansive approaches, for example,
instead of calling JQuery's \emph{toggle} to hide an element, 
we could add a CSS class which is defined as `display:none' to the element.
The first two solutions are not feasible because that requires us to either give up
mature CSS frameworks like Bootstrap or patching a huge number of existing \js{} libraries.
The third approach requires the developer have a good understanding of the libraries
he is using and deliberately code to avoid using style properties directly.
A more probable solution would be creating a better implementation of \emph{getComputedStyle} 
that is comparable with the implementation of a desktop web browser.

Another issue regarding to \jsdom{} is a internal function called \emph{lengthFromProperties} function 
performs poorly.
This function computes the children count of a DOM node and it will be called 
when the program reading a DOM NodeList Object's length property.
In the CPU profiling in Angular Chat application, 
this function could take more than 30\% CPU time during benchmark.%FIXME upgraded jsdom on oct.20, need to update this number
This problem can be avoid by deliberately avoid calling this function if necessary.
Like we discussed earlier, a better solution would is improving the existing implementation
of reading NodeList length property.

