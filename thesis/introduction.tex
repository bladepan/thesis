\chapter{Introduction}
\markright{Introduction}

\section{Motivation}

Most newly developed applications that provide a user interface to end users 
are web-based.  Modern browsers provide powerful and expressive user interface 
elements, allowing for rich applications, and the use of a networked
platform simplifies the distribution of these applications.  As a result,
researchers and practitioners alike have devoted a great deal of attention to
how to architect frameworks on this platform, which is characterized by the
use of the stateless HTTP protocol to transfer HTML-based user interface 
descriptions to the client along with JavaScript code, which in turn 
implements interactivity and communication with the application's backend tiers.

In many recently developed frameworks, much of the presentation logic of these applications
executes within the client's browser.  User input triggers events
which result in information being sent to a server and subsequent user interface updates.
Such updates are implemented as modifications to an in-memory tree-based
representation of the UI (the so-called document object model, or DOM), which
is then rendered by the browser's layout and rendering engine so the user can see it.
However, the state of the DOM is ephemeral in this model: when a user visits 
the same application later from the same or another device, or simply reloads the page, the state of the
DOM must be recreated from scratch.  In most existing applications, this 
reconstruction is done in an rudimentary and incomplete way, because
application programmers typically store only application state, and little 
or no presentation state in a manner that persists across visits.
As a result, many web applications do not truly feel like persistent,
``in-cloud'' applications to which a user can connect and disconnect at will.
By contrast, users are accustomed to features such as Apple's Continuity\cite{apple-continuity}
that allows them to switch between devices while preserving not only 
essential data, but enough of the applications' view to create the appearance
of seamlessly picking up from where they left off.

\cb{}~\cite{mcdaniel2012cloudbrowser} is a server-centric web framework 
that keeps the state of the HTML document in memory 
on the server in a way that is persistent across visits.
In this model, presentation state is kept in virtual browsers whose life
cycle is decoupled from the user's connection state.  When a user is connected,
a client engine mirrors the state of the virtual browser in the actual browser which
renders the user interface the user is looking at.  Any events triggered by the
user are sent to the virtual browser, dispatched there, and any updates
are reflected in the client's mirror.  This idea is reminiscent of 
``thin client'' designs used in cloud-based virtual desktop offerings,
but with the key difference that in this proposed design the presentation state
that is kept in a virtual browser is restricted to what can be represented at the
abstract DOM level; no flow layout or rendering is performed by the virtual browser on the 
server.

This model entails additional potential benefits: since only framework code runs in
the client engine, the application code running on the server does not need
to handle any client/server communication and can be written in an event-based
style similar to that used by desktop user interface frameworks.
Since the virtual browser has the same JavaScript execution capabilities as a
standard browser, emerging model-view-controller (MVC) frameworks such as 
AngularJS~\cite{hevery2009angular} can be directly used, further simplifying application development.
More side benefits include: a lighter weight client engine that can load faster,
a resulting application that is potentially more secure since no direct access to
application data needs to be exposed, the ability to co-browse by broadcasting
the virtual browser state to multiple clients.


\section{Core Contributions}

Prior to this work, the implementation of \cb{} was single threaded and
supported deployment on only one process. It could not scale horizontally by
adding more processors or more machines to increase the system's capacity. To
enable \cb{} to host large scale web applications, we designed and implemented
\cbtwo which can distribute virtual browsers  across the CPU cores of a
multiprocessor machine or across a cluster of machines.

We designed a single-master, multiple-workers architecture:
the master is responsible for application management and load balancing,
the workers host virtual browsers and serve user requests.
To facilitate the inter-process
communication among the processes in our system, we developed a remote procedure call
framework nodermi~\cite{nodermi} that encapsulates message communication as
method calls.
Nodermi transparently creates stubs that represent objects in other processes
and allows a process to invoke methods of other processes' objects by calling
methods on the stubs.
We also developed an application programming interface that fully
isolates application code from each other and from underlying systems code.

The underlying architecture change is transparent to applications. The new
implementation fully preserves the semantics of the existing programming model
while provide higher scalability. \cb{} applications do not need to be aware of
the distributed architecture on which they run.  Most of the existing applications 
can automatically scale to multiple processors without modification. Some
applications needed to be modified because of necessary changes to API methods'
signatures.

We have implemented a number of sample applications and profiled them to
better understand the intrinsic and extrinsic limitations of this design.  We
also built a benchmark tool that simulates multiple users interacting with the
applications and used it to evaluate the performance and scalability of
\cbtwo. In our experiments,  \cbtwo scales linearly, it supports 2,800
concurrent users using a chat room application on a eight core machine with
average latency under 100ms.

