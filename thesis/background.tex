\chapter{Background}
\markright{Background}

This chapter provides background information to understand the concepts
underlying the design of \cbtwo. We assume the reader has basic knowledge of
web-related protocols and languages, including HTTP~\cite{rfc7231},
HTML~\cite{hickson2012html},  DOM~\cite{2000Document},
\js~\cite{ecmascript2011ecmascript} and CSS~\cite{css21}.

\webscaleoutfig{}

\section{Scalable Web Server Architectures}
\label{sec:websys}

\cbtwo aims to provide a scalable platform for web applications.
In this section we introduce some typical methods to design
scalable architectures for web applications.

Web servers provide the infrastructure on which web applications 
are hosted.
Scalability is an important issue for web servers as the number of users
visiting a site can grow significantly even during short time spans~\cite{berners1998world}.
Even without an increase in users,
web applications may demand more resources as they become more sophisticated.

Figure~\ref{fig:webscaleout} shows a diagram of a typical scalable web server
architecture, which is able to harness resources from a cluster of servers. We
divide the servers in such a system into two layers. The web layer
processes HTTP requests from users and generates HTTP responses which will be
rendered in the user's browser. The web layer offloads storage and
computational tasks to a storage layer that consists of database servers or
other types of storage servers. The benefit of such layered design is twofold:
it makes the web servers lightweight so they are able to handle more
concurrent connections; the whole system becomes modular, so that the system
operator can upgrade parts of the system without interfering with other parts.

To balance requests evenly across the web servers, a load balancer component
sits between the clients and the web layer, which dispatches user requests to
web servers and returns the responses from the web servers to users. The use
of a load balancer allows users to access the web server using a single URL
because it hides the distributed architecture from the user. There are many
ways to implement load balancing~\cite{cardellini2002state}. For example, one can 
use round-robin DNS~\cite{} to distribute the load to a set of servers using 
distinct IP addresses.  The DNS server will rotate the list of addresses
returned, causing clients to connect to different machines.
%
DNS-based load balancing has a number of drawbacks:  
first, it is difficult to add or remove web servers since clients will
cache DNS information.  Second, it requires that all servers have public 
IP addresses so that they are directly reachable by clients.  

To overcome the limitations of DNS-based load balancing, system architects often 
add a layer of reverse proxies between the clients and the web servers. 
Reverse proxies (such as nginx~\cite{nginx})  forward user requests to one or
multiple web servers and copy responses from the web servers back to the users.

It is possible to have multiple reverse proxies and use DNS-based load
balancing among them.  User requests are
first distributed among the reverse proxies, then  the reverse proxies
distribute user requests across a larger number of web servers.

% \subsection{Application State Management}% maybe too big a title for a short review...

% We use application state to describe 
% the data web applications need to 
% process user requests and render user interface.
% Based on the design of the web application,
% the application state could comprise data fetched from some permanent
% storage or 
% generated during the execution of the application.
% On the other direction,
% the data in application state could be written back to permanent
% storage or just be kept transiently.
% The application state data that stored permanently could
% endure server restart and be referenced in the future,
% it usually contains data that is costly or impossible to 
% recreate, like user profile, shopping transactions, etc.
% The application state data that is transient 
% usually represents state that is acceptable to be lost
% during server restart or client crash.


% To distinguish individual users, the web application assigns 
% a unique session identifier for each user.
% The session identifier is then attached to every HTTP requests.


\subsection{Session State Management}

Web applications use session state to remember client-specific information across HTTP requests
so they can provide stateful services on top of the stateless HTTP protocol.
Web applications typically assign a unique session id for each user and 
use this session id to retrieve the user's session state for each request.
For the first request, the server automatically creates a new session for the user.
Applications store various bits of information in a user's session state,
such as authentication information, user profile, shopping carts, etc.

Most web frameworks provide two modes to manage session
state~\cite{phpdoc,j2eedoc}: a local mode where session state
is stored in memory or in the file system and a distributed mode where
session state is stored in a storage system, often a relational database.

If session state is stored locally, it can be accessed faster, but it is not
accessible from other web server instances.  To overcome this limitation, some
web servers like Tomcat support a session replication
mode~\cite{tomcatcluster} that  synchronizes locally stored session state
across a cluster of web servers.  Since a web server needs to
broadcast any changes to session state to all other web servers, this mode 
is expensive when there are many web servers.

Large scale web applications usually adopt distributed session state management.
Besides traditional relational databases,
the backend session storage could be implemented by high performance key value
stores such as Redis~\cite{redis} or distributed data stores 
such as Memcached~\cite{fitzpatrick2004distributed}, or 
Cassandra~\cite{lakshman2010cassandra}.

\subsection{Load Balancing}

The design choices regarding load balancing and their implementation can 
affect application development.  We use the taxonomy from the survey of Cardellini et
al.~\cite{cardellini2002state} to categorize load balancing approaches into client-
blind or client-aware, based on whether the load balancer uses information from
the client's request to perform the dispatch.

A client-blind load balancer does not use information from the client when
deciding how to dispatch a request. For example, it could randomly select a
web server from the web layer for each request, or use a round robin
algorithm. In this case, multiple requests from one client could be relayed to
different web servers. In this design, session state cannot be stored locally,
rather it must be accessible  from any server handling the client's request.
For every request, the web server needs to fetch the session state from
session storage and pushes the changes back to session storage if session
state is modified.

A client-aware load balancer dispatches every request from a given client to
the same web server. In this model, the web server can use a local mode
session state implementation, which is faster, but client-aware load balancers
can also benefit distributed session state implementations.
Since a given client's requests are dispatched to the same
server, the web server can cache session data to get better performance.  
In this way, a web server retrieves session state once for every user and
communicates with the storage system only when session data changes. The
downside of the client-aware load balancing approach is that the load balancer needs
to identify each client's assigned server to make the correct routing
decision. To that end, the load balancer needs to examine the HTTP request
header to extract the session identifier and assign web servers based on a
hash of this identifier.

Because different requests can impose different load on a web server, purely random 
or round-robin based approaches can cause uneven load distribution
among web servers. Especially for modern web applications with long
connections, the time a connection keeps open can vary from milliseconds to
hours. A naive load balancer could keep distributing requests to an already busy
server even when there are less loaded servers in the cluster. The load balancer 
can also be server-aware such that  it  takes servers' load information into
consideration when making dispatching decisions. Because client-aware load
balancing has the restriction of keeping requests from a given user to the
same server, server- and client-aware load balancing is more complex than
server-aware and client-blind load balancing.
 
% Another aspect that needs to be consider to design a scalable web system
% is the servers' load.
% The servers' load could be drastically uneven if the load balancer
% does not take the servers' state into the distribution process.

% Current web frameworks usually only deals with the Client Layer and the Web Layer,
% the web application developer should take the distribution policy of the load balancer
% into consideration when designing web applications,
% and they would need to configure or implement the load balancer to support
% the needs of the application.


% Current web frameworks do not have clear construct to define application state.
% One option for the developer is to rely on session objects provided by frameworks.
% The application developer needs to configure the persistence  of session objects
% and make sure the configuration works with the load distribution scheme.
% For example, in J2EE the session objects could be configured to be managed in memory or
% high available database~\cite{j2eedoc};
% in PHP developers could specify a session save handler to store session objects
% in database~\cite{phpdoc}.
% By default, these frameworks store session objects in memory or in local file system.
% If the developer adopts a client-blind load balancer,
% he needs to configure the session objects to use database or other
% synchronization mechanism to make sure the application state could be fetched on every server.
% Another option is to implement his own way of handling application state.
% Regardless of the choices of managing application state,
% the developer needs take the distribution policy of the load balancer
% into consideration when designing web applications,
% and in the other direction,
% the developer needs to find the right load balancer to support his application.






\section{\nodejs}

\cb is built on top of the \nodejs framework. \nodejs~\cite{tilkov2010node} is
a standalone \js runtime built on Google Chrome's V8~\cite{v8} \js engine that
allows \js code to be executed without a web browser.  \nodejs comes with a
standard library that provides API for file system access, network IO, binary
data manipulation, etc. It enables developers to write server-side network
applications in \js.  \nodejs is appealing for building high performance
scalable web applications because it adopts a non-blocking event-driven I/O
model which is capable of handling a large number of concurrent connections
using a single thread.

\nodejs has a thriving community with a variety of third party packages.
We have relied on multiple packages in \cb to implement complex tasks like
server side DOM manipulation as well as for many utility or formatting functions. 
Another reason we chose \nodejs is that we can write the \cb infrastructure 
in the same language as its applications, avoiding costs associated with
crossing languages.

In this section we discuss \nodejs's non-blocking I/O model and some
important third party packages we used.

 % it is not parallel with the next section
\subsection{Non-blocking I/O}

\js only has only one thread that executes \js code.
In this model if a function blocks then whole process blocks and cannot
do anything else.
It is very different from multiple-threaded languages like Java where
a thread can block on I/O the whole process can still do other things
via other threads.
To achieve concurrency, \js use a non-blocking I/O model based on a event queue.
In this model, I/O functions return immediately after issuing the I/O operations.
The runtime processes the I/O operations in the background and the code execution
thread continues after the I/O functions returns.
To get the result of an I/O function, the programmer need to register a callback
to be fired asynchronously.
The runtime places a new message with the callback function in the event queue after the I/O operation
completes.
The code execution thread polls the event queue in the event loop and fetches
one message at a time.
After the code execution thread fetches a message it will run its callback function
till completion before polling the event queue again.
In this way the program could concurrently performing multiple I/O tasks while executing
\js code.
% Besides I/O related functions, timers are also implemented using this event-driven model.

\begin{listing}[ht,width=\columnwidth]
\inputminted[
frame=lines,
fontsize=\scriptsize,
linenos
]
{javascript}{../codeexamples/readfile.js}
\caption{Reading file and printing the content on console using \nodejs.}
\label{code:nodefile}
\end{listing}

Listing~\ref{code:nodefile} shows an example of the non-blocking IO concept in \nodejs. 
Because the I/O API such as \code{readFile} does not block, 
the developer needs to pass a callback function to the \code{readFile} method  
that is invoked asynchronously when the I/O operation has completed.

% \js's execution model is based on a event queue and 
% a event loop.
% In the event loop, 
% the code execution thread fetches one message from the event queue at 
% a time and run the entire message to completion before fetching another message.
% Unlike multiple-threaded languages like JAVA where a thread can block on I/O
% operation while other threads can still progress,
% in this model if a function blocks it blocks the whole process because there
% is only one thread executes \js code.
% For this reason, the I/O functions are non-blocking in \js.
% The I/O functions return immediately after issuing the I/O operations.
% To get the result of an I/O operation, the programmer needs to pass
% a callback function to the I/O function and 
% after the I/O operation finishes a new message with the callback function will
% be placed on the event queue.
% In this way the program could concurrently performing multiple I/O tasks while executing
% \js code.

In this model, a function cannot be preempted since the runtime will
run the entire message to completion before running another.
The program is immune to the hard to debug problems brought by multi-thread
programming.
It is also easy to reason the behavior of individual functions as they cannot
be preempt.

A downside of this model is that it is hard to reason the execution order.
First, asynchronously callbacks may be executed in a order that is different 
from the order they are registered.
For example, in Listing~\ref{code:nodefile} the program called \code{readFile}
twice and it is possible that the callback for the second \code{readFile} be
executed first.
Second, it is impossible to tell from the function signature along if a 
callback will be called asynchronously via the event queue mechanism or be
called synchronously right away. In Listing~\ref{code:nodefile} line 10 is
be executed before line 3. If in the future \code{readFile} is updated such
that it caches files read before and calls the callback function right away
if the file in the parameter is cached, then line 3 will be executed before
line 10 if the file is cached and after line 10 if it is not.
Thus the programmer must take extra caution if the program depends on certain
execution order.

\begin{listing}[htb,width=0.8\columnwidth]
\inputminted[
frame=lines,
fontsize=\scriptsize,
linenos
]
{javascript}{../codeexamples/read2files.js}
\caption{Reading two files in a loop using \nodejs.}
\label{code:nodefile2}
\end{listing}


This asynchronous execution model requires the programmer to preserve the
application context in the callback functions' closure.  Sometimes it requires
subtle tricks that make the code hard to read. For example, suppose we want to
read a list of files and prints out the files' name and content. In
Listing~\ref{code:nodefile2}  line 3 - 10 shows a incorrect solution that
iterates an array of file names  and calls \code{readFile} with a callback
that prints the current file name and file content. The printed file name is
always the last file name because the callback functions registered in the
loop reference the \code{fileName} variable on the stack and it is updated
before these callbacks are triggered. Line 11 - 20 shows a correct
implementation  that includes a function that  stores the current file name in
the closure of the function it returns, it is harder to follow.


%callback hell

The prevalent asynchronous callbacks in \js are not intuitive for the
programmers that are used to traditional languages like Java or C. When
writing applications with complex logic, programmers often end up with deeply
nested callbacks which make the code hard to understand, the developer
community call it \emph{callback hell}. For example, to print the content of
two files one by one, a developer may call \code{readFile} with the callback
to print the second file  inside the callback of the first \code{readFile}
call. The nested callbacks get more convoluted for more complex task. Consider
the situation when a bootstrap function need to start various components in
the order that a competent must be started after all the components it depends
on are started.  To simplify the management of execution order of callbacks,
developers use libraries like async~\cite{async} (see
Section~\ref{sec:nodepackage}) when writing complex applications.


% We will briefly discuss async in Section~\ref{sec:nodepackage}.


\subsection{Important \nodejs Packages}
\label{sec:nodepackage}

\subsubsection{async}
Async is a library that helps developers implement complex control flow of asynchronous 
functions without nested callbacks. 
It supports various control flows such as calling asynchronous functions in
series, in parallel, in the order that meets predefined dependencies, etc.
The developers can focus on the implementation of individual steps
of control flows and async will make these steps be executed in the right order.


\subsubsection{Node-http-proxy}

Node-http-proxy~\cite{nodeproxy} is a \nodejs package for developing HTTP proxies.
It provides a programming interface to relay HTTP requests to another server and
automatically copy the response from that server to the original requester.
It also supports the WebSocket~\cite{rfc6455} protocol.
WebSocket is a TCP-based protocol which provides a bidirectional, full-duplex 
communication mechanism between web browsers and servers.
Using WebSockets, servers can send information to clients without requiring
a previous request by the client, unlike in traditional HTTP.
It also avoids the overhead of repeatedly establishing connections.

We use WebSockets to implement DOM synchronization between client and server so
the server can send DOM changes to clients.  In node-http-proxy,
the programmer needs only to provide the destination server on the hand shake
request and all the subsequent WebSocket messages will
be transparently proxied to the destination server.


Missing: motivation for using http-node-proxy instead of nginx as originally
planned?  Scalability? Easy of use?

Most of this section so far is really about what websockets are and our motivation
for using them? (Which should be discussed somewhere) 
Not about node-http-proxy.  Make separate section?  Different title?

\subsubsection{JSDom}

\emph{reads a little bit out of place... not sure we want this here separate...}

Jsdom~\cite{JSDOM} is a \nodejs package which provides a \js implementation of 
DOM API. We use jsdom to implement server side DOM tree.
Jsdom works like a web browser except it does not render the DOM tree:
it reads HTML documents to build the initial DOM tree,
it also executes \js files specified in script tags.
It is possible to create multiple jsdom instances in a same process,
each of these jsdom instance will have its own DOM tree and
script execution environment,
the scripts in each jsdom instance will have its own isolated view of global variables.
In our model, each virtual browser has one jsdom instance and
forwards client events to the jsdom DOM tree.
We also patched jsdom to get notifications for DOM updates.


\section{\cb}

\architectureoverview{}

In this section we sketch the implementation of
the original, single-process version \cb{}~\cite{mcdaniel2012cloudbrowser}.
Figure \ref{fig:cb1arch} shows the relationship
between the client engine running in the user's browser and the virtual browser
running server side.  When the user visits the application, the client engine
code is downloaded and restores the current view of the application by
copying the current state of the server document.  Subsequently, user input
is captured, forwarded to the server engine inside the virtual browser,
which then dispatches events to the document.  All application logic runs
in the global scope associated with the virtual browser's window object.
Since the server environment faithfully mimics a real browser, libraries
such as AngularJS~\cite{hevery2009angular} can be used unchanged to implement the user interface.
Client and server communicate through a lightweight RPC protocol that is
layered on top of a bidirectional WebSocket communication.
Stylesheets, images, etc. are provided to the client through a resource
proxy.

\subsection{Deployment Model}
\label{sec:deploymodel}
\appbundlefig{}
As shown in Figure~\ref{fig:appbundle}, 
a \cb application bundle is a directory
containing descriptor files, an entry point HTML file,
\js files and resource files such as CSS files, images, etc.
The descriptor files specify the application's name, owner, mount point, and
other application configuration information.
The mount point is the URL path to the application, for example,
if a \cb is deployed at \url{example.com} and an application's mount point is
\emph{chat}, the user could access the application at \url{http://example.com/chat}.
The \js files include libraries like AngularJS or JQuery, 
the application code and an optional application instance definition,
(further discussed in Section~\ref{sec:appins}).
Like in regular browser, the entry point HTML should have script tags
specifying the \js files the developer wants to be executed in a virtual browser.

Developers create application bundles, which can be deployed
from \cb's application directory or uploaded using \cb's administrative
interface.  Multiple applications could be deployed simultaneously.

\apphierarchyfig{}

\emph{You delve into application instances as if the user knows what this
    is - needs motivation here.  Similarly, haven't established definition
    of single virtual browser.
    Perhaps use motivating example - chatroom - to explain why we designed
    application instances.
    Perhaps this section can be reorganized by discussing the deployment
    scenario (already described below) first and using it as a motivator for 
    introducing the app instance idea.}

As emphasized in Figure~\ref{fig:appidhierarchy},
an application could create multiple application instances,
each application instance could create multiple virtual browsers,
a virtual browser could be simultaneously accessed by multiple clients.

% For example, in our chat room example application, multiple clients
% can join one chat room and each client get his own view of the
% chat room.
% In our model, the chat room concept is represented by application instance,
% the user's view of chat rooms are represented by virtual browsers.
% When a user request the chat room application's URL,
% he is redirected to a page that lists all the chat rooms(in essential application instances) 
% he joined.
% From there, the user could manage his application instances.
% He could create a new application instance(chat room) and share the application
% instance's URL to let others join in.
% When a user joined a chat room,
% a virtual browser is created for him so he could interact with the application.
% A virtual browser could also be accessed by multiple clients,
% the DOM updates from the virtual browser will be broadcast to all connecting
% clients to provide a co-browsing experience.

\subsection{Application Instance}
\label{sec:appins}
\appinstancefig{}


Application instance allows multiple virtual browsers to share data structure.
As in Figure~\ref{fig:appinstance} shows, 
every virtual browser is created inside an application instance
and virtual browsers inside an application instance share application instance object.
The application instance itself
consists metadata about the application instance object
 such as ownership and access permissions.
The application instance object is defined
the application instance definition file 
in the application bundle (see Figure~\ref{fig:appbundle}).
When a virtual browser is created in the application instance,
the application instance object is injected into that virtual browser
and the application code could reference it directly.

\chatappfig{}

As an example, consider a scenario for a Chat application developed using AngularJS,
depicted in Figure~\ref{fig:chatapp}.
A system administrator of a \cb deployment would install the application, which give users the
ability to create application instances. To start a chat site, a user would create
an application instance and share its URL with chat participants.  As the participants join
the chat site, a virtual browser is created on demand for each participant, which is connected
to the application instance (the users can bookmark their virtual browser's URL to later return.)
The shared application instance data in such an application
consist of the chatroom(s), users and their associated messages.  The advantage of this design
is that AngularJS's dirty-checking mechanism will reflect updates to the shared instance data
in each virtual browsers' document automatically, thus ensuring that new message are broadcast
to each.

\subsection{Authentication}

When an application is enabled with authentication, the system will redirect
the user's request to a login page if it detects the user has not logged in
that application. The login page itself is implemented by creating a virtual
browser in the system login application. The login page provides two
authentication options: a local authentication option where the user's
credentials are stored in MongoDB; an OAuth~\cite{hardt2012oauth} option which
authenticate user via Google's openID. The user could submit his email address
and password directly in the login page  for local authentication option. Then
the system will find the matching record in the account table.   For the OAuth
option, the user clicks a \emph{Login with Google Account} link  to land on a
Goolge account authorization page. After the user authorizes \cb{} to access
his Goolge account information, Goolge will request \cb{}'s authentication
callback URL and \cb{} will get the user's email address.

After the user logs in using either mode, the system adds an entry of the
user's email address and the application's mount point in the user's session
(stored in MongoDB as well). That entry indicates the user has logged in the
application. Then the login page virtual browser is closed and the user is
redirected to  the URL he originally requested. The subsequent requests from
the user will pass the authentication check until the session expires or the
user logs out the application.


\subsection{Application Instantiation Strategy}
\label{sec:appinstantiation}

The application instantiation strategy specifies
how the application instance and virtual browsers are instantiated.

Application programmers can create CloudBrowser applications in the same way in which
they create the client-side portion of a client-centric application, using low or high level
JavaScript libraries such as jQuery~\cite{jquery} or AngularJS.  
A descriptor in the application's manifest describes 
their application's instantiation strategy.
The supported strategies include

\begin{description}

\item[singleAppInstance] The application supports only one instance and single virtual browser.
    All connected clients will share a single server-side document in this singleton - this can be
    used for applications that display data, such as a weather application. These applications will not
    typically react to user input and users do not need to be authenticated.

\item[singleUserInstance]  This application requires authentication to establish a
    user identity, which we provide through a local database as well as through external OpenID
    authentication.   In this mode, users may not create more than one virtual browser per
    application instance.  When a user accesses the application instance's URL, they will either
    be forwarded to their virtual browser or a virtual browser will be instantiated for them.

\item[multiInstance]
    Allows users to have multiple, separate virtual browsers connected to an application
    instance. For instance, a user may have to be in two separate chatrooms offered by one chat site.
    In those cases, the user has the largest flexibility, but will need to manage whether
    to join an existing virtual browser or create a new one when they visit the application instance
    - similar to the choice a user may have when deciding whether to navigate to a new site in
    an existing browser tab or open a new one.

\end{description}

Except for multiInstance applications, the existence of virtual browsers is not exposed to
end users that merely join existing application instances.


% The hierarchy that results from applications, application instances, and virtual browsers is
% depicted in Figure~\ref{fig:appidhierarchy}.  This figure shows the general case in which an
% application might allow multiple instances, and in which each user can create multiple virtual
% browsers.


