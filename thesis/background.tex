\chapter{Background}
\markright{Background}

This chapter provides background information to understand the concepts
underlying the design of \cbtwo. We assume the reader has basic knowledge of
web-related protocols and languages, including HTTP~\cite{rfc7231},
HTML~\cite{hickson2012html},  DOM~\cite{2000Document},
\js~\cite{ecmascript2011ecmascript} and CSS~\cite{css21}.

\webscaleoutfig{}

\section{Scalable Web Server Architectures}
\label{sec:websys}

\cbtwo aims to provide a scalable platform for web applications.
In this section we introduce some typical methods to design
scalable architectures for web applications.

Web servers provide the infrastructure on which web applications 
are hosted.
Scalability is an important issue for web servers as the number of users
visiting a site can grow significantly even during short time spans~\cite{berners1998world}.
Even without an increase in users,
web applications may demand more resources as they become more sophisticated.

Figure~\ref{fig:webscaleout} shows a diagram of a typical scalable web server
architecture, which is able to harness resources from a cluster of servers. We
divide the servers in such a system into two layers. The web layer
processes HTTP requests from users and generates HTTP responses which will be
rendered in the user's browser. The web layer offloads storage and
computational tasks to a storage layer that consists of database servers or
other types of storage servers. The benefit of such layered design is twofold:
it makes the web servers lightweight so they are able to handle more
concurrent connections; the whole system becomes modular, so that the system
operator can upgrade parts of the system without interfering with other parts.

To balance requests evenly across the web servers, a load balancer component
sits between the clients and the web layer, which dispatches user requests to
web servers and returns the responses from the web servers to users. The use
of a load balancer allows users to access the web server using a single URL
because it hides the distributed architecture from the user. There are many
ways to implement load balancing~\cite{cardellini2002state}. For example, one can 
use round-robin DNS~\cite{} to distribute the load to a set of servers using 
distinct IP addresses.  The DNS server will rotate the list of addresses
returned, causing clients to connect to different machines.
%
DNS-based load balancing has a number of drawbacks:  
first, it is difficult to add or remove web servers since clients will
cache DNS information.  Second, it requires that all servers have public 
IP addresses so that they are directly reachable by clients.  

To overcome the limitations of DNS-based load balancing, system architects often 
add a layer of reverse proxies between the clients and the web servers. 
Reverse proxies (such as nginx~\cite{nginx})  forward user requests to one or
multiple web servers and copy responses from the web servers back to the users.

It is possible to have multiple reverse proxies and use DNS-based load
balancing among them.  User requests are
first distributed among the reverse proxies, then  the reverse proxies
distribute user requests across a larger number of web servers.

% \subsection{Application State Management}% maybe too big a title for a short review...

% We use application state to describe 
% the data web applications need to 
% process user requests and render user interface.
% Based on the design of the web application,
% the application state could comprise data fetched from some permanent
% storage or 
% generated during the execution of the application.
% On the other direction,
% the data in application state could be written back to permanent
% storage or just be kept transiently.
% The application state data that stored permanently could
% endure server restart and be referenced in the future,
% it usually contains data that is costly or impossible to 
% recreate, like user profile, shopping transactions, etc.
% The application state data that is transient 
% usually represents state that is acceptable to be lost
% during server restart or client crash.


% To distinguish individual users, the web application assigns 
% a unique session identifier for each user.
% The session identifier is then attached to every HTTP requests.


\subsection{Session State Management}
\label{sec:sessionmanage}

Web applications use session state to remember client-specific information across HTTP requests
so they can provide stateful services on top of the stateless HTTP protocol.
Web applications typically assign a unique session id for each user and 
use this session id to retrieve the user's session state for each request.
For the first request, the server automatically creates a new session for the user.
Applications store various bits of information in a user's session state,
such as authentication information, user profile, shopping carts, etc.

Most web frameworks provide two modes to manage session
state~\cite{phpdoc,j2eedoc}: a local mode where session state
is stored in memory or in the file system and a distributed mode where
session state is stored in a storage system, often a relational database.

If session state is stored locally, it can be accessed faster, but it is not
accessible from other web server instances.  To overcome this limitation, some
web servers like Tomcat support a session replication
mode~\cite{tomcatcluster} that  synchronizes locally stored session state
across a cluster of web servers.  Since a web server needs to
broadcast any changes to session state to all other web servers, this mode 
is expensive when there are many web servers.

Large scale web applications usually adopt distributed session state management.
Besides traditional relational databases,
the backend session storage could be implemented by high performance key value
stores such as Redis~\cite{redis} or distributed data stores 
such as Memcached~\cite{fitzpatrick2004distributed}, or 
Cassandra~\cite{lakshman2010cassandra}.

\subsection{Load Balancing}

The design choices regarding load balancing and their implementation can 
affect application development.  We use the taxonomy from the survey of Cardellini et
al.~\cite{cardellini2002state} to categorize load balancing approaches into client-
blind or client-aware, based on whether the load balancer uses information from
the client's request to perform the dispatch.

A client-blind load balancer does not use information from the client when
deciding how to dispatch a request. For example, it could randomly select a
web server from the web layer for each request, or use a round robin
algorithm. In this case, multiple requests from one client could be relayed to
different web servers. In this design, session state cannot be stored locally,
rather it must be accessible  from any server handling the client's request.
For every request, the web server needs to fetch the session state from
session storage and pushes the changes back to session storage if session
state is modified.

A client-aware load balancer dispatches every request from a given client to
the same web server. In this model, the web server can use a local mode
session state implementation, which is faster, but client-aware load balancers
can also benefit distributed session state implementations.
Since a given client's requests are dispatched to the same
server, the web server can cache session data to get better performance.  
In this way, a web server retrieves session state once for every user and
communicates with the storage system only when session data changes. The
downside of the client-aware load balancing approach is that the load balancer needs
to identify each client's assigned server to make the correct routing
decision. To that end, the load balancer needs to examine the HTTP request
header to extract the session identifier and assign web servers based on a
hash of this identifier.

Because different requests can impose different load on a web server, purely random 
or round-robin based approaches can cause uneven load distribution
among web servers. Especially for modern web applications with long
connections, the time a connection keeps open can vary from milliseconds to
hours. A naive load balancer could keep distributing requests to an already busy
server even when there are less loaded servers in the cluster. The load balancer 
can also be server-aware such that  it  takes servers' load information into
consideration when making dispatching decisions. Because client-aware load
balancing has the restriction of keeping requests from a given user to the
same server, server- and client-aware load balancing is more complex than
server-aware and client-blind load balancing.
 
% Another aspect that needs to be consider to design a scalable web system
% is the servers' load.
% The servers' load could be drastically uneven if the load balancer
% does not take the servers' state into the distribution process.

% Current web frameworks usually only deals with the Client Layer and the Web Layer,
% the web application developer should take the distribution policy of the load balancer
% into consideration when designing web applications,
% and they would need to configure or implement the load balancer to support
% the needs of the application.


% Current web frameworks do not have clear construct to define application state.
% One option for the developer is to rely on session objects provided by frameworks.
% The application developer needs to configure the persistence  of session objects
% and make sure the configuration works with the load distribution scheme.
% For example, in J2EE the session objects could be configured to be managed in memory or
% high available database~\cite{j2eedoc};
% in PHP developers could specify a session save handler to store session objects
% in database~\cite{phpdoc}.
% By default, these frameworks store session objects in memory or in local file system.
% If the developer adopts a client-blind load balancer,
% he needs to configure the session objects to use database or other
% synchronization mechanism to make sure the application state could be fetched on every server.
% Another option is to implement his own way of handling application state.
% Regardless of the choices of managing application state,
% the developer needs take the distribution policy of the load balancer
% into consideration when designing web applications,
% and in the other direction,
% the developer needs to find the right load balancer to support his application.






\section{\nodejs}

\cb is built on top of the \nodejs framework. \nodejs~\cite{tilkov2010node} is
a standalone \js runtime built on Google Chrome's V8 \js engine~\cite{v8} that
allows \js code to be executed without a web browser.  \nodejs comes with a
standard library that provides API for file system access, network I/O, binary
data manipulation, and others. It enables developers to write server-side network
applications in \js.  \nodejs is appealing for building high performance
scalable web applications because it adopts a non-blocking, event-driven I/O
model which is capable of handling a large number of concurrent connections
using a single thread.

\nodejs has a thriving community with a variety of third party packages.
We have relied on multiple packages in \cb to implement complex tasks such as
server side DOM manipulation as well as for many utility or formatting functions. 
Another reason we chose \nodejs is that we are able to write the \cb infrastructure 
in the same language as its applications, avoiding costs associated with
crossing languages.

In this section we discuss \nodejs's non-blocking I/O model and some
important third party packages we used.

 % it is not parallel with the next section
\subsection{Non-blocking I/O}

A \js engine has only one thread that executes \js code.
In this model, if a function blocks on some operation such as I/O,
then whole process blocks and cannot make progress.
By contrast, in a multi-threaded languages such as Java only the
current thread is blocked whereas other threads within the same process can
still make progress.
To avoid blocking and achieve concurrent execution of multiple tasks, 
\js uses a non-blocking I/O model based on a event queue.
In this model, I/O functions return immediately after issuing I/O requests.
The runtime processes I/O operations in the background 
and keeps track of when they complete.  Upon completion, an
event is scheduled that, when executed, will fire a programmer-provided
callback function.
In this way, the program can concurrently performing multiple I/O tasks 
while executing \js code.

The execution thread polls the event queue in the event loop, processing
events in order.  The handlers/callback functions associated with each
event must run to completion.  This lack of preemption means that 
\js code is immune from the race conditions that arise in preemptive,
multi-threaded environments, and makes it simpler to reason about
the behavior of individual functions.

% Besides I/O related functions, timers are also implemented using this event-driven model.

\begin{listing}[ht,width=\columnwidth]
\inputminted[
frame=lines,
fontsize=\scriptsize,
linenos
]
{javascript}{../codeexamples/readfile.js}
\caption{Reading a file and printing its content using \nodejs.}
\label{code:nodefile}
\end{listing}

Listing~\ref{code:nodefile} shows an example of the non-blocking I/O concept in \nodejs. 
Because the I/O API such as \code{readFile} does not block, 
the developer needs to pass a callback function to the \code{readFile} method  
that is invoked asynchronously when the I/O operation has completed.

% \js's execution model is based on a event queue and 
% a event loop.
% In the event loop, 
% the code execution thread fetches one message from the event queue at 
% a time and run the entire message to completion before fetching another message.
% Unlike multiple-threaded languages like JAVA where a thread can block on I/O
% operation while other threads can still progress,
% in this model if a function blocks it blocks the whole process because there
% is only one thread executes \js code.
% For this reason, the I/O functions are non-blocking in \js.
% The I/O functions return immediately after issuing the I/O operations.
% To get the result of an I/O operation, the programmer needs to pass
% a callback function to the I/O function and 
% after the I/O operation finishes a new message with the callback function will
% be placed on the event queue.
% In this way the program could concurrently performing multiple I/O tasks while executing
% \js code.

Although event handler run to completion, the order in which events fire
is unpredictable.  As a result, it can be hard to reason about a program's
execution order.
Asynchronous callbacks may be executed in a order that is different 
from the order in which they were registered.
For example, in Listing~\ref{code:nodefile} the program called \code{readFile}
twice but it is possible that the callback for the second \code{readFile} call
is executed first.
It is also impossible to tell from the function signature alone if a 
callback will be called asynchronously via the event queue mechanism or if
it could be called synchronously. In Listing~\ref{code:nodefile} line 10 is
be executed before line 3 if readFile's callback fires asynchronously. 
If, in the future \code{readFile} were changed such
that it caches the contents of files, it may call the callback function synchronously
if it finds cached data in a request, so line 3 will be executed before line 10.
Thus the programmer must take extra caution to not depend on a certain execution
order.

\begin{listing}[htb,width=0.8\columnwidth]
\inputminted[
frame=lines,
fontsize=\scriptsize,
linenos
]
{javascript}{../codeexamples/read2files.js}
\caption{Reading two files in a loop using \nodejs.}
\label{code:nodefile2}
\end{listing}


This asynchronous execution model requires the programmer to preserve the
application context in the callback functions' closure.  This process
is prone to subtle mistakes.  For example, suppose we want to
read a list of files and print out each file's name and content.
Listing~\ref{code:nodefile2}  lines 4--11 shows a incorrect solution that
iterates over an array of file names and calls \code{readFile} with a callback
that prints the current file name and file content. 
If the callback fires synchronously, filename will refer to the currently
read file. If, however, the callback fires asynchronously - as it likely will
in the current implementation of \code{readFile}, filename will refer to the
name of the last file in the list.
Line 13--22 shows a correct implementation that dynamically creates a function 
that references the current file name in its closure.
Though correct, the resulting code is more difficult to read.

%callback hell

The prevalence of asynchronous callbacks in \js is not intuitive for
programmers that are used to languages like Java or C that provide blocking I/O 
primitives.
When writing applications with complex logic, programmers often end up with deeply
nested callbacks which make their code hard to understand, something which has
been referred to by the developer community as \emph{callback hell}. 

For instance, to read two files in order, the program in Listing\ref{code:nodefile2} could
be changed such that the I/O for the second file is initiated in the callback
that is fired when the first file has been read, which adds a level of nesting.
However, this approach will not allow the I/O of those files to overlap.
To handle this situation and more complex scenarios, developers frequently use 
libraries like async~\cite{async}. % (see Section~\ref{sec:nodepackage}).

% We will briefly discuss async in Section~\ref{sec:nodepackage}.

\subsection{\nodejs Packages Used in \cb}
\label{sec:nodepackage}

\subsubsection{Async}
\emph{Async} is a library that helps developers implement complex control 
flow patterns of asynchronous functions without nested callbacks.
It supports various recurring patterns, including
execution in series, in parallel, or in an order that meets predefined dependencies,
and others.
The developers can focus on the implementation of individual steps
and \emph{async} will execute them in the right order, while simultaneously 
documenting the desired semantics.

For example, to compute the combined size of multiple files,
it is necessary to read these files in parallel, add each file's size 
to a running total, and then output the total sum after every file is read. 
Listing~\ref{code:async_each} shows two implementations,
lines 5--14 implement a barrier-style counter in vanilla \js, whereas 
lines 15--21 uses async's \code{each} function, which provides parallel 
iteration over an array. 
Although this is a simple use case, the use of \emph{async} makes the
intended control flow pattern more clear and includes proper exception
handling.

\begin{listing}[htb,width=0.8\columnwidth]
\inputminted[
frame=lines,
fontsize=\scriptsize,
linenos
]
{javascript}{../codeexamples/async_each.js}
\caption{Print the total size of multiple files using async.}
\label{code:async_each}
\end{listing}


\subsubsection{Node-http-proxy}

In \cbtwo, we needed to implement a reverse proxy that allows us to specify
destination servers for incoming HTTP requests.
Furthermore, we required the ability to add and remove forwarding rules programmatically.
Existing standalone reverse proxy software such as nginx 
rely on pre-defined URL matching rules and support only fixed dispatch policies 
such as round-robin when selecting destination servers.
We found this software too difficult to adapt to achieve the required behavior.

Node-http-proxy~\cite{nodeproxy} is a \nodejs package that helps developers to 
implement customizable reverse proxy software.
It allows the developer to write customized logic to implement specific
forwarding policies for incoming HTTP requests and provides the necessary
code to handle the network communication for proxying these requests.

It also supports the WebSocket~\cite{rfc6455} protocol.
WebSocket is a TCP-based protocol which provides a bidirectional, full-duplex 
communication mechanism between web browsers and servers.
Using WebSockets, servers can send information to clients without requiring
a previous request by the client, unlike in traditional HTTP.
It also avoids the overhead of repeatedly establishing connections.
We use WebSockets to implement DOM synchronization between clients and server.
In node-http-proxy,
the programmer needs to provide the destination server only for the hand shake
request that establishes the connection, then all subsequent WebSocket messages will
be transparently proxied to the destination server.  
This feature greatly simplified our implementation.

\subsubsection{Jsdom}


Jsdom~\cite{JSDOM} is a \nodejs package which provides a \js implementation of the
DOM API. % We use jsdom to implement the server side DOM tree.
Jsdom works like a web browser except it does not render the DOM tree:
it reads HTML documents to build the initial DOM tree and executes \js files specified in script tags.
It is possible to create multiple jsdom instances in the same process,
each of these jsdom instance will have its own DOM tree and
isolated namespace for its \js code.


\section{\cb}

\architectureoverview{}

This section reviews the implementation of
the original, single-process version \cb{}~\cite{mcdaniel2012cloudbrowser},
which formed the basis for this work.
Figure \ref{fig:cb1arch} shows the relationship
between the client engine running in the user's browser and the virtual browser 
(implemented using jsdom)
running server side.  When the user visits an application, the client engine
code is downloaded, which then restores the current view of the application by
copying the current state of the server document.  Subsequently, user input
is captured, forwarded to the server engine inside the virtual browser,
which then dispatches events to the document.  All application logic runs
in the global scope associated with the virtual browser's window object.
Since the server environment faithfully mimics a real browser, libraries
such as AngularJS~\cite{hevery2009angular} can be used unchanged to implement 
the user interface.
Client and server communicate through a lightweight RPC protocol that is
layered on top of a bidirectional WebSocket communication channel.
Stylesheets, images, etc. are provided to the client through a resource
proxy.  The client's browser is responsible for rendering the document
on the screen using the provided styles.


\subsection{Deployment Model}
\label{sec:deploymodel}

\appbundlefig{}

\cb uses an application server model.  Application code is packaged in
bundles in a well-defined format.
Developers create application bundles, which can be deployed
from \cb's application directory or uploaded using \cb's administrative
interface.  Multiple applications can be deployed simultaneously.

Figure~\ref{fig:appbundle} shows an example of an \cb application bundle
contained in a directory.
The bundle includes descriptor files, an entry point HTML file,
\js files and resource files such as CSS files, images, etc.
The descriptor files specify the application's name, owner, mount point, and
other application configuration information.
The mount point is the URL path to the application, for example,
if a \cb is deployed at \url{example.com} and an application's mount point is
\emph{chat}, the user could access the application via \url{http://example.com/chat}.
The \js files include libraries like AngularJS or JQuery, 
the application code and an optional \emph{application instance definition}
file (detailed later).
Like in regular browser, the entry point HTML can have script tags
specifying the \js files the developer wants to be executed.

% motivation
\chatappfig{}

\appinstancefig{}

%
Application execution in \cb is organized via \emph{application
instances} and \emph{virtual browsers}.  
We motivate these abstractions using the following use case scenario.
Consider a Chat application developed using
AngularJS, as depicted in Figure~\ref{fig:chatapp}. After a \cb administrator 
installs this application, authorized users will have the ability to
create chatrooms and join existing chatrooms.  Each user who has joined is
provided with its own view.
These views are represented as virtual browsers in \cb. 

Virtual browsers in the same chatroom must share related session state such
as chatroom's title, chatting history, etc. Simultaneously, it should be
possible for multiple users to create separate, unrelated chatrooms.
\cb provides \appins to achieve this behavior. Application instance state 
can be shared by multiple virtual browsers. The developer
describe the state underlying an \appins{} in the \emph{application instance
definition} file in the application bundle. For the chat application, this state
may include the messages and participants of one or more chatrooms shared
by these participants, see Figure~\ref{fig:appinstance}. 

To create a chatroom, a user would create an \appins{} and share
its URL with chat participants. As the participants join the chat site, a
virtual browser is created on demand for each participant, which is connected
to the application instance (the users can bookmark their virtual browser's
URL to later return.) The virtual browser can directly access the \appins
that contains the shared chatroom-related state, which simplifies the 
synchronization between this state and the virtual browser's DOM.

\apphierarchyfig{}

Thus in our model, 
an application can have multiple \appins{}s,
each \appins{} can have multiple virtual browsers.
It is also possible for multiple clients to simultaneously access a virtual browser,
although in this case all users will see exactly the same UI 
(See Figure~\ref{fig:appidhierarchy}).


% For example, in our chat room example application, multiple clients
% can join one chat room and each client get his own view of the
% chat room.
% In our model, the chat room concept is represented by application instance,
% the user's view of chat rooms are represented by virtual browsers.
% When a user request the chat room application's URL,
% he is redirected to a page that lists all the chat rooms(in essential application instances) 
% he joined.
% From there, the user could manage his application instances.
% He could create a new application instance(chat room) and share the application
% instance's URL to let others join in.
% When a user joined a chat room,
% a virtual browser is created for him so he could interact with the application.
% A virtual browser could also be accessed by multiple clients,
% the DOM updates from the virtual browser will be broadcast to all connecting
% clients to provide a co-browsing experience.




\subsection{Authentication}
\label{sec:auth}

\cb provides support for common authentication-related features
to applications, such as registering user accounts, external authentication
through outside providers, and maintains a authentication state transparently
and outside the actual application code.

The application developer can enable authentication support for an
application by setting the authentication option in the application's descriptor.
The system will then redirect the user to a login page if the
user has not been authenticated.
Applications can access the user's account information via the \cb API 
once the user has logged in.

The login page itself is implemented by a virtual
browser representing the system's login application. The login page provides two
authentication options: a local authentication option where the user's
credentials are stored in a local database, for \cb supports local account creation and lookup.
Second, and an OAuth~\cite{hardt2012oauth} option which
authenticate users via Google's openID authentication services. 
In this option, the user clicks a \emph{Login with Google Account} button which redirects
to a Google account authorization page asking the user to authorize \cb{} to access
the user's Google account information.
After the user confirms Google will request \cb{}'s authentication
callback URL to finalize the authentication.

After the user logs in using either mode, the system adds an entry of the
user's email address and the application's mount point to the user's session.
% That entry indicates the user has logged in the application. 
Then the login page virtual browser is closed and the user is
redirected to the URL he originally requested. 
For all subsequent requests of this session, the system will detect the user has 
logged in and the requests are handling directly by the application.

The user is automatically logged out after the session expires.
The application can also display a link to the application's logout URL 
in the user interface to allow the user to manually logout the application.

\subsection{Application Instantiation Strategy}
\label{sec:appinstantiation}

Different types of applications need different strategies with regard to how to 
create \appins{}s and virtual browsers.
These strategies differ with respect to how many instances there can be
per application, and how many virtual browsers a user may create for each
application instance.

%A chat application may use multiple \appins{} to represent multiple chatrooms
%and support multiple virtual browsers for each \appins{} to provide separate user
%interfaces for the users in the associated chatroom.  However, each authenticated
%user is allowed only one virtual browser per chatroom \appins{}.
%A todo-list application may need only one virtual browser for each user to 
%display the user's todo-lists.

\cb{} provides four application instantiation strategies that
specify different ways to initiate \appins{}s and virtual browsers.
The developer can set the application to adopt one of the application instantiation 
strategies in the application's descriptor.

\begin{description}

\item[multiInstance]
    This is the most flexible option, which
    allows users to have multiple, separate virtual browsers connected to an application
    instance. For instance, a user could participate using separate nicknames in a chatroom.
    In those cases, the user has the largest flexibility, but will be exposed to having
    to manage the virtual browsers created for them.  For instance, when visiting a chatroom
    application instance, they will need to manage whether
    to join an existing virtual browser or create a new one
    - similar to the choice a user may have when deciding whether to navigate to 
    a new site in an existing browser tab or open a new one.
    In this model, there are also no restrictions on the number of instances created
    for an application.

\item[singleBrowserPerUser]  
    In this mode, users may not create more than one virtual browser per
    application instance.  When users access the application instance's URL, they will either
    be forwarded to their virtual browser or a virtual browser will be instantiated for them.
    This has the advantage that users will not be exposed to the management of 
    virtual browsers - the application will appear to them as a standard web application
    whose URL they can bookmark.
    An example might be a chatroom application that only allows users to participate
    under a single nickname in each instance.
    This instantiation mode requires user authentication to establish a user's identity. 

\item[singleInstancePerUser] 
    Whereas multiInstance and singleBrowserPerUser support an arbitrary number of
    application instance per application, and thus require the explicit creation and
    management of application instances, singleInstancePerUser applications support only
    a single application instance per user, which is automatically created on demand.
    singleInstancePerUser applications also limit users to a single virtual browser
    for their instance, in the same way singleBrowserPerUser instances do.
    This mode is ideal for modeling single-page web applications in which only one 
    view is needed for each user.
    This instantiation mode  requires authentication to establish a user's identity. 

\item[singleAppInstance] The application supports only one instance and a single virtual browser
    that is shared by all users.
    All connected clients will share a single server-side document in this singleton mode - this can be
    used for applications that display data, such as a weather application. These applications will not
    typically react to user input and users do not need to be authenticated.

\end{description}

\instantiationStrategyTbl{}

Table~\ref{tab:appinstantiationstrategy} summarizes how many \appins{}s and virtual browsers
each initiation strategy allows applications to create.

For \emph{singleUserInstance} and \emph{multiInstance} applications where the user
needs to manually create \appins{}s, the system provides landing pages where the user 
could view and manage his \appins{}s and virtual browsers.
For instance, in a chat application, if the user requests the application's URL,
he is redirected to the application's landing page where all the
 chatrooms (i.e. \appins{}s) he is participating are listed,
from there the user can create new \appins{}s, delete existing \appins{}s, share
\appins{}s with other users, etc.


% The hierarchy that results from applications, application instances, and virtual browsers is
% depicted in Figure~\ref{fig:appidhierarchy}.  This figure shows the general case in which an
% application might allow multiple instances, and in which each user can create multiple virtual
% browsers.


