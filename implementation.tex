\section{Design and Implementation}
\label{sec:implementation}
As shown in Figure~\ref{fig:cb2arch}, a \cb{} system consists of one master node and multiple worker nodes.
The worker node hosts virtual browsers which execute application code and create server
side DOM structures.
The virtual browsers in a same worker node are grouped into \appins{}s,
we will explain \appins{} in detail in section~\ref{sec:appins}.
All the clients' requests go through master node which dispatches the requests to
worker nodes.
Master node and worker nodes run on separate processes and communicate with each other
via TCP messages.
The new design could be deployed to multiple servers or a single server.

Like in any other web framework, the user access the hosted web application by entering
a URL in his web browser.
The user could use any of the below URL types to access an application.
\begin{enumerate}
\item \label{itm:appurl} http://example.com/[app] : Application URL.
`app' is application specified mount point. For example, a chat application's mount point URL
might be http://example.com/chat.
\item \label{itm:appinsurl} http://example.com/[app]/a/[appInstanceId] : \appins{} URL.
`appInstanceId' is id of a \appins{}. For example,
\appins{} 1 in chat application has the URL http://example.com/chat/a/1.
access \appins{} 1 in chat application.
\item \label{itm:vburl} http://example.com/[app]/a/[appInstanceId]/b/[browserId] : Browser URL.
`browserId' is id of a virtual browser. For example, virtual browser 2 is inside \appins{} 1 of
chat application, so that virtual browser's URL is http://example.com/chat/a/1/b/2.
\end{enumerate}
If the user requests an Application URL or an \appins{} URL, 
\cb{} will try to allocate a virtual browser for the request,
after that, the system will send a redirect response containing a Browser URL to the user.
When the user requests a Browser URL,
the system will dispatch the request to the worker node hosts the corresponding virtual browser,
the user will receive a bootstrap HTML document containing links to client engine code just as
the original design.
After the client engine is initialized, the client engine will send requests
to master node to establish web socket connection.
All the client server communication afterwards are transmitted via web socket.
%The client engine is fully aware of the current \appins{} id and virtual browser id, 
%all the HTTP requests initiated by the client engine will attach those ids in the URL.



\newarchitectureoverview{}




\subsection{Master}
Figure~\ref{fig:dispatch} presents the dispatch logic of the master node.
When the master receives a request from client,
it first tries to extract \appins{} id from the request URL.
If the request is associated with an \appins{},
the master will look up a in memory mapping table to find the worker
who hosts the \appins{} and forward the request to it.
If this request is not associated with an \appins{},
the master would pick a worker node to forward this request.
In this case, the worker node would use application specific logic to handle this request.
For example, if the application is configured as create only one virtual browser per user,
the worker node will find a existing virtual browser of that user or create a new one
and send a redirect response to make the client's web browser request that virtual browser's URL.
A virtual browser's URL always contains an \appins{} id.
After dispatching the request,
the master will relay response message from worker node to client.

It is noticeable that the majority of the client server traffic are web socket messages,
those messages are transmitted via an established web socket that is already connected to the 
correct worker node.
So the master only execute this dispatch logic before the client engine bootstrapped.

For simplicity, all the client traffic and the workers' responses goes through master node.
We use an open source \nodejs{} module node HTTP proxy~\cite{nodeproxy} to implement
an embedded HTTP proxy inside master node.
The embedded HTTP proxy listens on the ports that clients connect to,
when the proxy receives a HTTP request,
it will call a method to get the target worker node and then relay the message
to the worker node.
We also considered to use high performance HTTP reverse proxy nginx~\cite{nginx}
to relaying requests,
but to do so we need to modify the code of nginx to 
make it talks to master node before relaying requests,
also it would make the deployment of \cb{} more complex.
On the other hand, the embedded HTTP proxy could directly invoke master's methods.
However, as the embedded HTTP proxy runs on the same thread as the master's other
components, the master could be overwhelmed under heavy load.
This could be alleviated by using \nodejs{}'s Cluster API to make the embedded HTTP
proxy to run on multiple processes.

\requestdispatchdiagram{}

\subsubsection{Load Balancing}
To make the work load as evenly distributed to the worker nodes as possible,
the master node assign a integer weight value to each worker
and the worker with the smallest weight will be picked to handle new requests
or create new \appins{}.
To make the weight value reflect the actual load of the worker,
the worker node sends heartbeat message containing 
its heapUsed value to master every 3 seconds(
the heapUsed value is the total size of \js{} objects that have not been
reclaimed by garbage collector, 
it is a more accurate indicator of the worker's load than resident memory size
).
The master stores the heapUsed in megabytes as the worker's weight.
To avoid a burst of workload all being directed to a fixed worker.
Every time the master node forward requests or send create \appins{} command to a worker,
the weight value of that node will be incremented by an empirical amount.
For example, if there are two workers w1 and w2 in the system with weight
100 and 101 respectively,
before the next heartbeat message the master received ten requests to 
create \appins{},
if we do not increase the worker's weight after forwarding a request,
we end up let w1 handles all the work,
if we increase the worker's weight by 10 for each \appins{} created,
we distribute these ten requests evenly.
Even if the number we add to the weight does not accurately amount to the actual 
heapUsed of the worker, it will be fixed after receiving the next heart beat message.

\subsection{Worker}
\label{sec:worker}
When worker node receives a request from the master,
one of the following could happen:

\begin{enumerate}
    \item The request belongs to a \appins{} on the worker.
    \begin{enumerate}
        \item It is associated with a virtual browser in the \appins{}, directs this request to the virtual browser.
        \item It is not associated with any virtual browser in the \appins{}, create a virtual browser for the request
        and let the new virtual browser handle this request.
    \end{enumerate}

    \item The request does not belong to any \appins{} on this worker.
    \begin{enumerate}
        \item The request belongs to an \appins{} on another worker.
        Send back response to client with a redirect HTTP header field
        containing URL to that \appins{}.
        \item Worker asks Master for a new \appins{},
        the master will choose a most free worker node to create an new \appins{},
        then the original worker will send back a response with a redirect HTTP header field
        containing URL to the new \appins{}.
    \end{enumerate}

    \item The request is rejected because it violates permission rules or application specific rules.
    \begin{enumerate}
        \item The request is associated with a virtual browser or \appins{} but
        the request is from a client who does not have access right to those resource.
    \end{enumerate}
\end{enumerate}


\subsection{\appins{}}
\label{sec:appins}
% program model, programmer retrieve and keep session data, responsible for session data management
% php, dynamoDB session handler
One challenge to expand a web application to multiple processes is
how to store \emph{session data}.
We refer \emph{session data} as semi-permanent
application state associated with a user session.
Considering a simple chat application:
the user could join a chat room by visiting the chat room's URL,
he could see recent messages posted by other people joined in the chat room,
he could also update his nickname and post new messages.
The user's nick name and recent messages are session data
because these information need to be kept around for page rendering
during the user's session.
If this chat application only runs on one process,
we could just keep all the session data in memory and access
them directly.
This method does not work
if we want to scale out this chat application to increase the application's capacity.
Like in figure~\ref{fig:multiappservers},
one common solution is to introduce load balancer to dispatch
requests from clients among application servers and
use a centralized session server to serve the session data~\cite{j2eedoc,chlan2002internet,chiang2001transparent,saigo2003session}.
The advantage of this solution is that the load balancer can use
a simple algorithm like round robin to dispatch the requests.
The disadvantage is that the user's requests could hit different
servers and the server needs to fetch session data from the session server
for every request to get the most recent session data.
Some methods~\cite{shachor2005maintaining} are devised to create session affinity,
that is the requests from a session are sent to the same application
server so application could cache session data locally to avoid communicating with
session server for every quest.
For the chat application in particular,
the recent messages in a chat room could be modified by multiple user sessions,
so the session affinity solutions should also make sure all the requests within
a chat room are dispatched to the same application server.
In \cb{}, we created \appins{} mechanism to provide an easy and high performance
way to manage session data.

\multiappservers{}

% detailed explain here
Every virtual browser needs to be created inside an \appins{}.
When worker creates an \appins{},
application could create a customized \appins{} object to hold session data.
The \appins{} object could be directly referenced and manipulated like any plain
\js{} object by application code running inside virtual browsers.
Figure~\ref{fig:appinstance} shows an example of how a chat application would
utilize \appins{}.
In this application, the \appins{} object stores the state of a chat room.
It has a property called ``Messages'' represents recent messages and a method ``PostMessage''
to add new message.
Each virtual browser in the \appins{} represents a user's view of the chat room.
The application code could use ``Messages'' in the \appins{} object to draw
a list of chat history,
and call the ``PostMessage'' method when the user submit a new message.
There is no need to create session affinity or caching session data,
the virtual browsers in the same \appins{} are guaranteed to be created on the same process.



\appinstancefig{}

%We also provide a in-memory data sharing mechanism called App Instance for use cases that need better performance than database.
%User could define
%For the shared data that does not need to be persisted,
%But for some temporary data, this could be expensive





\subsection{Remote Method Invocation}
In \cb{} programming API and some internal module, there are use cases like list all the App Instances in an application
and terminate a virtual browser.
In the single process version, these operations would be accomplished by simple local method invocation
since all the objects are in the same process.
For multiple processes,
we need substitute direct method invocation with message communication between processes.
In the meantime, we want to preserve the code structure as much as possible,
and we do not want to do a huge code refactor each time we decide to access some more types of objects remotely.


To solve this problem,
we developed a Node.js library nodermi~\cite{nodermi} to handle the complexity of accessing a remote object.
We will use the term \emph{client} referring to the process that needs to access a remote object,
the term \emph{server} referring to the process that provides that object.
The client access the remote object's properties or methods through a stub object generated by nodermi.
The stub object cashes all the remote object's properties,
so for the property access there is no message communication involved.
For methods,
the stub object will send method invocation message to server and handle response or error under the hood.
All objects returned~\footnote{Here 'return' does not mean using return keyword, it means using a callback function to pass back the result.} by remote method invocation
 except simple type objects like string or date are serialized in the server side
 and reincarnated as a stub object in the client side.

% https://Node.jsmodules.org/tags/rmi
There are some existing rmi libraries for Node.js.
To our best knowledge, none of which could satisfy all the use cases we need.
Nodermi is capable of handling some complex use cases involving multiple servers and clients.
Consider the following use case:
Server A has an object A,
Server B has a method called listAllObjects that would return an array contains object A,
Server C calls Server B's listAllObjects method and get a reference of object A,
then C invokes object A's method method1.
Nodermi is able to recognize object A is from server A and server C will talk to server A directly.
However other rmi libraries fails to do such optimization.
Besides, we could specify properties to omit during serialization using nodermi,
this could significantly reduce the message size in our system.

\subsection{Synchronous Vs. Asynchronous}
Due to the single thread nature of Node.js,
it is critical that remote method invocations do not block the main thread.
So the underlying IO operations for RMI need to be performed asynchronously.
Consequently, the result of an RMI could only be read asynchronously.
If the caller code need a RMI to return a result,
the only way is get the result through a callback function
after it is read from a remote server.
Conventionally in Node.js, an asynchronous executed method
accept a callback function as its last parameter.
Nodermi takes advantage of this knowledge and handle methods with callback parameter transparently
~\footnote{A method with a callback parameter is not necessarily a asynchronous method,
but for the caller there is no difference if the method execute the callback synchronously or asynchronously}.
But for a method that is originally use return keyword to the caller,
we need to change its signature to add a callback function as a parameter and
replace the return statement with a call to the callback. % TODO add a fig for this
We also have to refactor the code of the corresponding RMI to use callback instead of
directly assignment.



\begin{listing}[ht,width=0.3\textwidth]
\begin{minted}[
frame=lines,
fontsize=\scriptsize,
linenos
]
{javascript}
var a = someService.getSomeObject1(key);

someService.getSomeObject2(a,
    function(err, result){
        //do something with result
    }
);
\end{minted}
\caption{Code sample from single process \cb{}}
\label{code:single}
\end{listing}

\begin{listing}[ht,width=0.3\textwidth]
\begin{minted}[
frame=lines,
fontsize=\scriptsize,
linenos
]
{javascript}
// getSomeObject1 is refactored
// to use a callback
someService.getSomeObject1(key,
    function(err, a){
        if(err){
            throw err;
        }
        // getSomeObject2's signature
        // could remain the same
        someService.getSomeObject2(a,
            function(err, result){
                //do something with result
            }
        );
    }
);
\end{minted}
\caption{Code sample from multiple process \cb{}}
\label{code:multi}
\end{listing}
